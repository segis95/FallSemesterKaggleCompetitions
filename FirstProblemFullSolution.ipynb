{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sc\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first type preprocessing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test_ids = test[\"id\"]\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)\n",
    "\n",
    "train_y = train['target']\n",
    "train_x = train.drop('target', axis = 1)\n",
    "\n",
    "categorial = []\n",
    "binary = []\n",
    "continues = []\n",
    "\n",
    "for f in train_x.columns:         \n",
    "    # Defining the level\n",
    "    if 'bin' in f:\n",
    "        binary.append(f)\n",
    "    elif 'cat' in f:\n",
    "        categorial.append(f)\n",
    "    elif train[f].dtype == float:\n",
    "        continues.append(f)\n",
    "    else:\n",
    "        categorial.append(f)\n",
    "        \n",
    "for c in categorial:\n",
    "    temp = pd.concat([pd.Series(train_y), pd.Series(train_x[c])],axis = 1)\n",
    "    freqs = temp.groupby(by = c).agg([\"mean\"])\n",
    "    dic = freqs.to_dict()[('target', 'mean')]\n",
    "    dic = defaultdict(lambda: 0.0, dic)\n",
    "    L = [dic[x] for x in train_x[c]]\n",
    "    try:\n",
    "        K = [dic[x] for x in test[c]]\n",
    "    except(KeyError):\n",
    "        print(dic)\n",
    "        print(c)\n",
    "        break\n",
    "    test[c] = K\n",
    "    train_x[c] = L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second type preprocessing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(X_train):\n",
    "    multreg = X_train['ps_reg_01'] * X_train['ps_reg_03'] * X_train['ps_reg_02']\n",
    "    ps_car_reg = X_train['ps_car_13'] * X_train['ps_reg_03'] * X_train['ps_car_13']\n",
    "    X_train = X_train.drop(['ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n",
    "                            'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11', 'ps_calc_12',\n",
    "                            'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin',\n",
    "                            'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin', 'ps_car_10_cat', 'ps_ind_10_bin',\n",
    "                            'ps_ind_13_bin', 'ps_ind_12_bin'], axis=1)\n",
    "    X_train['mult'] = multreg\n",
    "    X_train['ps_car'] = ps_car_reg\n",
    "    X_train['ps_ind'] = X_train['ps_ind_03'] * X_train['ps_ind_15']\n",
    "    return X_train\n",
    "\n",
    "train_x1 = pd.read_csv('train.csv')\n",
    "train_y1 = train_x1['target']\n",
    "train_x1 = train_x1.drop(['id', 'target'], axis=1)\n",
    "test_x1 = pd.read_csv('test.csv')\n",
    "test_x1 = test_x1.drop(['id'], axis=1)\n",
    "\n",
    "train_x1 = preproc(train_x1)\n",
    "test_x1 = preproc(test_x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eta'] = 0.02\n",
    "param['silent'] = True\n",
    "param['max_depth'] = 5\n",
    "param['subsample'] = 0.8\n",
    "param['colsample_bytree'] = 0.8\n",
    "param['eval_metric'] = 'auc'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of xgboost-adapted datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train_x.values, train_y.values)\n",
    "dtest = xgb.DMatrix(test.values)\n",
    "\n",
    "dtrain1 = xgb.DMatrix(train_x1.values, train_y1)\n",
    "dtest1 = xgb.DMatrix(test_x1.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the first...\n",
      "[0]\teval-auc:0.608587\ttrain-auc:0.608587\n",
      "Multiple eval metrics have been passed: 'train-auc' will be used for early stopping.\n",
      "\n",
      "Will train until train-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.636312\ttrain-auc:0.636312\n",
      "[200]\teval-auc:0.648939\ttrain-auc:0.648939\n",
      "[300]\teval-auc:0.659013\ttrain-auc:0.659013\n",
      "[400]\teval-auc:0.667754\ttrain-auc:0.667754\n",
      "[500]\teval-auc:0.675751\ttrain-auc:0.675751\n",
      "[600]\teval-auc:0.682439\ttrain-auc:0.682439\n",
      "[700]\teval-auc:0.688498\ttrain-auc:0.688498\n",
      "[800]\teval-auc:0.694206\ttrain-auc:0.694206\n",
      "[900]\teval-auc:0.699469\ttrain-auc:0.699469\n",
      "[999]\teval-auc:0.704642\ttrain-auc:0.704642\n",
      "Training the second...\n",
      "[0]\teval-auc:0.606893\ttrain-auc:0.606893\n",
      "Multiple eval metrics have been passed: 'train-auc' will be used for early stopping.\n",
      "\n",
      "Will train until train-auc hasn't improved in 100 rounds.\n",
      "[100]\teval-auc:0.632807\ttrain-auc:0.632807\n",
      "[200]\teval-auc:0.644641\ttrain-auc:0.644641\n",
      "[300]\teval-auc:0.656568\ttrain-auc:0.656568\n",
      "[400]\teval-auc:0.665429\ttrain-auc:0.665429\n",
      "[500]\teval-auc:0.672311\ttrain-auc:0.672311\n",
      "[600]\teval-auc:0.678028\ttrain-auc:0.678028\n",
      "[700]\teval-auc:0.683093\ttrain-auc:0.683093\n",
      "[800]\teval-auc:0.687841\ttrain-auc:0.687841\n",
      "[900]\teval-auc:0.692294\ttrain-auc:0.692294\n",
      "[999]\teval-auc:0.696963\ttrain-auc:0.696963\n"
     ]
    }
   ],
   "source": [
    "evallist  = [(dtrain,'eval'), (dtrain,'train')]\n",
    "evallist1  = [(dtrain1,'eval'), (dtrain1,'train')]\n",
    "\n",
    "print('Training the first...')\n",
    "clf  = xgb.train(param, dtrain, 1000, evallist, early_stopping_rounds=100, maximize=True, verbose_eval=100)\n",
    "\n",
    "print('Training the second...')\n",
    "clf1 = xgb.train(param, dtrain1, 1000, evallist1, early_stopping_rounds=100, maximize=True, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making prediction and saving the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(dtest)\n",
    "pred1 = clf1.predict(dtest1)\n",
    "\n",
    "res = 0.5 * (pred + pred1)\n",
    "res = pd.concat([test_ids, pd.Series(res)],axis = 1)\n",
    "res.columns = ['id', 'target']\n",
    "res.to_csv('PB1XGB1+XGB2.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
